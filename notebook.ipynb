{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning\n",
    "This tutorial is based on the official tutorial titled [Working With Data](http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html) by the `scikit-learn` team and a similarly-minded [tutorial](https://github.com/jonhare/WAIS-ML101) conducted by Dr Jonathon Hare in 2016. Compared to those versions, the current tutorial features a dataset that has been published by [Kaggle](https://www.kaggle.com) as part of a competition that they organised for [Detecting Insults in Social Commentary](https://www.kaggle.com/c/detecting-insults-in-social-commentary). Furthermore, a number of changes have been carried in the code of the above-mentioned tutorials in order to include `pandas` in the data pre-processing stage, and to assure compatibility with the updated version of `scikit-learn`.\n",
    "\n",
    "In this tutorial you will learn how to:\n",
    "* Extract feature vectors from text documents\n",
    "* Load, inspect and pre-process a dataset of comments on social media\n",
    "* Train a classifier to predict whether a comment on social media is insulting or not\n",
    "* Use Grid Search in order to tune better the hyper-parameters of your Machine Learning pipeline\n",
    "\n",
    "In order to run this iPython Notebook (Python 2), [Jupyter](http://jupyter.org/) should be installed in your machine. Besides Jupyter, the following Python packages should also be installed: (i) `pandas` and (ii) `scikit-learn`. The easiest way to install all of these together is with [Anaconda](https://www.anaconda.com/) (Windows, macOS and Linux installers available)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Kaggle Dataset\n",
    "For the purposes of this tutorial, we will be using a dataset of comments on social media along with their classification labels (i.e. \"insult\" or \"neutral\"). The dataset is encoded in binary-encoded `pickle` files which reside in `./Kaggle/train.p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_dataset_location = './Kaggle/train.p' # The location of the Kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "\n",
    "# Loading the binary-encoded pickle files from the designated location.\n",
    "with open(kaggle_dataset_location, 'rb') as f:\n",
    "    kaggle_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `kaggle_dataset` variable contains the dataset as a pythonic dictionary of lists. We will be using the `pandas` library in order to tranform this structure into a `pandas.DataFrame` which will simplify the data inspection and pre-processing process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3947\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "kaggle_dataset_df = pd.DataFrame(kaggle_dataset)\n",
    "print len(kaggle_dataset_df) # Number of rows in the loaded DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the first 10 rows of the `DataFrame` in order to get an understanding of the structure of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Class                                            Comment  \\\n",
      "3937  neutral  Your Yellowstone Fly Fishing Report:\\n\\n.. The...   \n",
      "3938  neutral  MrO,\\n\\nProof is shown by liberals not wanting...   \n",
      "3939  neutral  The only ignorant person here is you, who thin...   \n",
      "3940  neutral               oh i had many cars like this before.   \n",
      "3941  neutral  @Sara Besleaga Griji, doruri sau dorin\\\\xc8\\\\x...   \n",
      "3942   insult    you are both morons and that is never happening   \n",
      "3943  neutral  Many toolbars include spell check, like Yahoo ...   \n",
      "3944  neutral  @LambeauOrWrigley\\xa0\\xa0@K.Moss\\xa0\\nSioux Fa...   \n",
      "3945  neutral  How about Felix? He is sure turning into one h...   \n",
      "3946  neutral  You're all upset, defending this hipster band....   \n",
      "\n",
      "                 Date  \n",
      "3937  20120619145323Z  \n",
      "3938  20120612001129Z  \n",
      "3939  20120619205630Z  \n",
      "3940  20120610114639Z  \n",
      "3941              NaN  \n",
      "3942  20120502172717Z  \n",
      "3943  20120528164814Z  \n",
      "3944  20120620142813Z  \n",
      "3945  20120528205648Z  \n",
      "3946  20120515200734Z  \n"
     ]
    }
   ],
   "source": [
    "print kaggle_dataset_df.tail(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i really don't understand your point.\\xa0 It seems that you are mixing apples and oranges.\n",
      "@jdstorm dont wish him injury but it happened on its OWN and i DOUBT he's injured, he looked embarrassed to me\n"
     ]
    }
   ],
   "source": [
    "print kaggle_dataset_df['Comment'][1]\n",
    "print kaggle_dataset_df['Comment'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Class', u'Comment', u'Date'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print all the available columns of the dataset.\n",
    "print(kaggle_dataset_df.columns)\n",
    "# Define the target column which we want to predict.\n",
    "target_column = u'Class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the category codes of each of the classes in the target-column.\n",
    "inputs = kaggle_dataset_df['Comment']\n",
    "outputs = kaggle_dataset_df['Class'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'insult', u'neutral']\n"
     ]
    }
   ],
   "source": [
    "class_names = kaggle_dataset_df['Class'].astype('category').cat.categories.tolist()\n",
    "print class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very important to gain a basic understanding about how potentially imbalanced towards certain classes our dataset is before moving further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049 comments that are labeled as insult.\n",
      "2898 comments that are labeled as neutral.\n"
     ]
    }
   ],
   "source": [
    "for cl in class_names:\n",
    "    print '%d comments that are labeled as %s.' % (len(kaggle_dataset_df[kaggle_dataset_df['Class'] == cl]), cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the performance of our algorithm, we should test its performance on data that it hasn't *seen* during training. Luckily, `scikit-learn` includes an appropriate function that splits the items for a dataset into random train and test subsets.\n",
    "\n",
    "We set the portion of the original dataset that will be used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.2\n",
    "# Set a random_state number for replicability of the experiments.\n",
    "random_state = 10\n",
    "# Split dataset into training and testing according to the test_size variable.\n",
    "# output_train and output_test are lists containing the classes' indices.\n",
    "input_train, input_test = train_test_split(inputs.tolist(), test_size=test_size, random_state=random_state)\n",
    "y_train, y_test = train_test_split(outputs.tolist(), test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Features from Text: The Bag-of-Words Approach\n",
    "In order to be able to use text documents$^1$ as either input to Machine Learning algorithms, we need to follow a process that would turn them into numerical feature vectors. We generally refer to this process as *vectorisation*. The most intuitive way to do so is the **bags-of-words** approach, which is carried out as follows:\n",
    "1. Identify all the words that occur in the documents of a training set.\n",
    "2. Assign a fixed integer ID to each one of those words. For example in Python you could build a dictionary that would map each word to each corresponding integer ID:\n",
    " ```python\n",
    " dictionary = {'I': 1,\n",
    "               'study': 2,\n",
    "               'machine': 3,\n",
    "               'learning': 4,\n",
    "               ...}\n",
    " ```\n",
    "3. For each document in the training set, we count the number of occurrences of each word, and we store it in $X[d, w]$, as the value of the $w$-th feature for the $d$-th document, where $w$ is the index of the word in the dictionary.\n",
    "\n",
    "The bags-of-words representation implies that total number of features is the number of distinct words in the corpus, which typically is larger than 100k. \n",
    "\n",
    "While storing all these values in a `numpy` array would require substantial amount of memory, most values in $X$ will be zeros since for a given document only a small subset of the set of the distinct words in the dataset will be present. For this reason, we say that bags-of-words are typically high-dimensional sparse datasets. We can save a lot of memory by only storing the non-zero parts of the feature vectors in memory. `scipy.sparse` matrices are data structures that do exactly this, and scikit-learn has built-in support for these structures.\n",
    "\n",
    "In `scipy` text preprocessing, tokenising and stop-words (e.g. \"and\", \"or\" and \"that\") filtering are included in a high-level component that is able to build a dictionary of features and transform documents to feature vectors:\n",
    "\n",
    "$^1$ Text documents can vary substantially in length and writing style. In our case, we refer to text documents as the short-lengthed comments of our Kaggle dataset, but the techniques presented in this tutorial could work on much longer collections, such as articles or books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# The lines below load the TweetTokenizer from the nltk library.\n",
    "# You can comment-them-in along with the tokenizer variable of\n",
    "# the CountVectorizer should you like to see the results with\n",
    "# a different tokeniser.\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "# word_tokenizer = TweetTokenizer(preserve_case=False, \n",
    "#                                 strip_handles=True, \n",
    "#                                 reduce_len=True).tokenize\n",
    "\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1, 1),\n",
    "                                   stop_words=None,\n",
    "                                   # tokenizer=word_tokenizer,\n",
    "                                   # Ignore terms that have a document frequency strictly higher than the given threshold.\n",
    "                                   # If float, the parameter represents a proportion of documents, integer absolute counts.\n",
    "                                   max_df=1.0,\n",
    "                                   # Ignore terms that have a document frequency strictly lower than the given threshold.\n",
    "                                   # If float, the parameter represents a proportion of documents, integer absolute counts.\n",
    "                                   min_df=1)\n",
    "count_vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on a Toy Example\n",
    "Let’s use it to tokenize and count the word occurrences of a minimalistic corpus of text documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_corpus = [u'You have studied Machine Learning',\n",
    "              u'I love learning Machine Learning',\n",
    "              u'Looking forward to #WAISAwayDay',\n",
    "              u'Have you studied Machine Learning']\n",
    "\n",
    "# Fits and tranforms the corpus in its bag-of-words representation.\n",
    "toy_count = count_vectorizer.fit_transform(toy_corpus) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the fitting process each team is assigned a unique integer index corresponding to a column in the resulting `toy_count` matrix (i.e. equivalent to the $X$ matrix that has been mentioned in the description of this section of the tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 9)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 2)\t2\n",
      "  (1, 5)\t1\n",
      "  (2, 8)\t1\n",
      "  (2, 7)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 3)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 5)\t1\n",
      "  (3, 6)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 9)\t1\n",
      "[[0 1 1 0 0 1 1 0 0 1]\n",
      " [0 0 2 0 1 1 0 0 0 0]\n",
      " [1 0 0 1 0 0 0 1 1 0]\n",
      " [0 1 1 0 0 1 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print toy_count # This is the memory-efficient representation of a sparse matrix.\n",
    "print toy_count.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the first and the last rows of the array are identical. This is happening because they correspond to comments with the same words, and, thus, are encoded in equal vectors, which leads to loss of valuable information. `CountVectorizer` also supports counts of n-grams of words or consecutive characters. N-grams are runs of consecutive characters or words, so for example in the case of word bi-grams, every consecutive pair of words would be a feature. Support for n-grams can be enabled by adjusting the `ngram_range` variable during the initialisation of the `CountVectorizer`.\n",
    "\n",
    "In the initialisation of `CountVectorizer` set the `ngram_range` variable to `(1, 2)`, and check the resulting `toy_count` matrix by running `toy_count.toarray()`. Do the results make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interpretation of the columns can be retrieved as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'forward',\n",
       " u'have',\n",
       " u'learning',\n",
       " u'looking',\n",
       " u'love',\n",
       " u'machine',\n",
       " u'studied',\n",
       " u'to',\n",
       " u'waisawayday',\n",
       " u'you']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the vectoriser is fitted, you can retrieve the index (starting from zero) of a particular word in the dictionary by simply calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.vocabulary_.get(u'machine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further details about the functionality of `CountVectorizer`, please refer [here](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on the Kaggle Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u\"Only if Ronald McDonald gives him time off from his regular job as a McSlave at McDoonald's.\",\n",
       " u\"You're a fucking joke.\",\n",
       " u'Magic Number, Magic Underpants = No Big Deal',\n",
       " u\"YOU HAVE A BEAUTIFUL BODY. What's wrong with a man looking at a woman with a beautiful body ESPECIALLY NICE HIPS? If I'm stalker for that then every dude I know is a stalker as well.\",\n",
       " u'So, now we know what you are by your own identification, fool, will you kindly moveon.org and stop cluttering up the place and so we intelligent posters can post?']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a small part of the comments that will be used for training.\n",
    "input_train[:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# The lines below load the TweetTokenizer from the nltk library.\n",
    "# You can comment-them-in along with the tokenizer variable of\n",
    "# the CountVectorizer should you like to see the results with\n",
    "# a different tokeniser.\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "# word_tokenizer = TweetTokenizer(preserve_case=False, \n",
    "#                                 strip_handles=True, \n",
    "#                                 reduce_len=True).tokenize\n",
    "\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1, 1),\n",
    "                                   stop_words=None,\n",
    "                                   # tokenizer=word_tokenizer,\n",
    "                                   # Ignore terms that have a document frequency strictly higher than the given threshold.\n",
    "                                   # If float, the parameter represents a proportion of documents, integer absolute counts.\n",
    "                                   max_df=1.0,\n",
    "                                   # Ignore terms that have a document frequency strictly lower than the given threshold.\n",
    "                                   # If float, the parameter represents a proportion of documents, integer absolute counts.\n",
    "                                   min_df=1)\n",
    "count_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fits and tranforms the corpus in its bag-of-words representation.\n",
    "X_train_count = count_vectorizer.fit_transform(input_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the fitting process each team is assigned a unique integer index corresponding to a column in the resulting `X_train_count` matrix (i.e. equivalent to the $X$ matrix that has been mentioned in the description of this section of the tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3157, 14315)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print X_train_count.shape\n",
    "print X_train_count.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Occurrences To Frequencies\n",
    "Occurrence count is a good start. However, longer documents will have higher average count values than shorter documents, even though they might talk about similar topics. To avoid these potential discrepancies, it suffices to divide the number of occurrences of each word in a document by the total number of words in the document. The number of times a term occurs in a document, divided by the number of terms in a document is called the **term frequency** (**tf**).\n",
    "\n",
    "Another refinement on top of term frequency is to downscale weights for words that occur in many documents in the corpus, and are therefore less informative than those that occur only in a smaller portion of the corpus. In order to achieve this we can weight terms on the basis of the **inverse document frequency** (**idf**). The *document frequency* is the number of documents a given word occurs in; the inverse document frequency is often defined as the total number of documents in the corpus divided by the document frequency.\n",
    "\n",
    "Combining tf and idf results in a *family of weightings* (tf is usually multiplied by idf, but there a few different variations of how idf is computed) known as **term frequency-inverse document frequency** (**tf–idf**).\n",
    "\n",
    "Both tf and tf–idf on our `toy_corpus` can be computed using `scikit-learn` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'You have studied Machine Learning',\n",
       " u'I love learning Machine Learning',\n",
       " u'Looking forward to #WAISAwayDay',\n",
       " u'Have you studied Machine Learning']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 10)\n",
      "[[0.   0.2  0.2  0.   0.   0.2  0.2  0.   0.   0.2 ]\n",
      " [0.   0.   0.5  0.   0.25 0.25 0.   0.   0.   0.  ]\n",
      " [0.25 0.   0.   0.25 0.   0.   0.   0.25 0.25 0.  ]\n",
      " [0.   0.2  0.2  0.   0.   0.2  0.2  0.   0.   0.2 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Computing tf using the counts that have been computed from the CountVectorizer.\n",
    "tf_transformer = TfidfTransformer(use_idf=False, norm='l1', smooth_idf=False)\n",
    "X_train_tf = tf_transformer.fit_transform(toy_count)\n",
    "\n",
    "print X_train_tf.shape\n",
    "print X_train_tf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 0, 1, 1, 0, 0, 1],\n",
       "       [0, 0, 2, 0, 1, 1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 1, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 1, 1, 0, 0, 1, 1, 0, 0, 1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_count.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 10)\n",
      "[[0.         0.22118748 0.16821878 0.         0.         0.16821878\n",
      "  0.22118748 0.         0.         0.22118748]\n",
      " [0.         0.         0.41210174 0.         0.38184739 0.20605087\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.25       0.         0.         0.25       0.         0.\n",
      "  0.         0.25       0.25       0.        ]\n",
      " [0.         0.22118748 0.16821878 0.         0.         0.16821878\n",
      "  0.22118748 0.         0.         0.22118748]]\n"
     ]
    }
   ],
   "source": [
    "# Computing tf-idf using the counts that have been computed from the CountVectorizer.\n",
    "tfidf_transformer = TfidfTransformer(use_idf=True, norm='l1', smooth_idf=False)\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(toy_count)\n",
    "\n",
    "print X_train_tfidf.shape\n",
    "print X_train_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than transforming the raw counts with the `TfidfTransformer`, it is alternatively possible to use the `TfidfVectorizer` to directly parse the dataset. We compute tf-idf scores on the Kaggle dataset as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3157, 1853)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer(ngram_range=(1, 1),\n",
    "                             stop_words='english',\n",
    "                             # tokenizer='word_tokenizer',\n",
    "                             # Ignore terms that have a document frequency strictly higher than the given threshold.\n",
    "                             # If float, the parameter represents a proportion of documents, integer absolute counts.\n",
    "                             max_df=0.75,\n",
    "                             # Ignore terms that have a document frequency strictly lower than the given threshold.\n",
    "                             # If float, the parameter represents a proportion of documents, integer absolute counts.\n",
    "                             min_df=5,\n",
    "                             # tf-idf parameters\n",
    "                             use_idf=True, norm='l1', smooth_idf=False)\n",
    "\n",
    "X_train_tfidf = tfidf_vect.fit_transform(input_train)\n",
    "\n",
    "print X_train_tfidf.shape\n",
    "print X_train_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try filtering out terms that are either too frequent or infrequent in the dataset by adjusting the `max_df` and `min_df` variable respectively. This is an easy way of not only filtering out the less informative words but also reducing the number of features (less storage complexity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Predictive Model using K-Nearest-Neighbours\n",
    "Now that we have our training features and the labels of each post, we can train a classifier to predict whether a message is insulting or not. Let's start with a KNN classifier, which provides a simple baseline, although is perhaps not the best classifier for this task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3).fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try to predict the outcome on a new comment we need to extract the features using almost the same feature extracting chain as before. The differences are that we call (i) `transform` instead of `fit_transform` on the transformer or vectoriser, and (ii) `predict` on the classifier since they have both been fit to the training set.\n",
    "\n",
    "You can test your own comments by changing the text in the `test_comment` variable. Does your classifier identify all the insults properly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are a moron: insult\n"
     ]
    }
   ],
   "source": [
    "test_comment = 'you are a moron'\n",
    "test_comment_tfidf = tfidf_vect.transform([test_comment])\n",
    "y_pred = knn_clf.predict(test_comment_tfidf)\n",
    "\n",
    "print'%s: %s' % (test_comment, class_names[y_pred[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Performance on the Test Set\n",
    "We will be evaluating the performance of our KNN classifier on the *unseen* data of the test set based on the accuracy metric. In a binary classification task, such as ours, the accuracy with which a model predicts a specific class $c$ (e.g. insults) is formally defined as:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\sum \\text{TP} + \\sum \\text{TN}}{\\sum \\text{TP} + \\sum \\text{FP} + \\sum \\text{TN} + \\sum \\text{FN}}\n",
    "\\end{align}\n",
    "where:\n",
    "* $\\text{TP}$ refers to True Positive predictions: both the predicted and the empirical labels are $c$\n",
    "* $\\text{TN}$ refers to True Negative predictions: both the predicted and the empirical labels are $\\neq c$\n",
    "* $\\text{FP}$ refers to False Positive predictions: the predicted label is $c$ but the empirical label $\\neq c$\n",
    "* $\\text{FN}$ refers to False Negative predictions: the predicted label is $\\neq c$ but the empirical label is $c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "X_test_tfidf = tfidf_vect.transform(input_test)\n",
    "y_pred = knn_clf.predict(X_test_tfidf)\n",
    "print 'Accuracy: %.2f' % (metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Pipeline\n",
    "In order to make our pipeline (i.e. vectoriser or transformer $\\rightarrow$ classifier) easier to work with, `scikit-learn` provides the `Pipeline` class that behaves like a compound classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "clf_pipeline = Pipeline([('tfidf', TfidfVectorizer(ngram_range=(1, 1),\n",
    "                                               stop_words='english',\n",
    "                                               # tokenizer=word_tokenizer,\n",
    "                                               # If float, the parameter represents a proportion of documents, integer absolute counts.\n",
    "                                               max_df=1.0,\n",
    "                                               # Ignore terms that have a document frequency strictly lower than the given threshold.\n",
    "                                               # If float, the parameter represents a proportion of documents, integer absolute counts.\n",
    "                                               min_df=5,\n",
    "                                               # tf-idf parameters\n",
    "                                               use_idf=True, norm='l1', smooth_idf=False)),\n",
    "                         ('clf', KNeighborsClassifier(n_neighbors=3))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names `tfidf` and `clf` (classifier) are arbitrary. We shall see their use in the section on grid search, below. We can now train (on the training set) and test (on the test set) the model in a similar fashion to when we had all the different components separate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "clf_pipeline.fit(input_train, y_train)\n",
    "y_pred = clf_pipeline.predict(input_test) # We are making prediction on the test set.\n",
    "print 'Accuracy: %.2f' % (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can do better with a linear Support Vector Machine (SVM). We can change the learner by just plugging a different classifier object into our pipeline as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.float64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.75, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=F...om_state=10, shuffle=True, tol=1e-05,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf_pipeline = Pipeline([('tfidf', TfidfVectorizer(ngram_range=(1, 1),\n",
    "                                               stop_words='english',\n",
    "                                               # tokenizer=word_tokenizer,\n",
    "                                               # If float, the parameter represents a proportion of documents, integer absolute counts.\n",
    "                                               max_df=0.75,\n",
    "                                               # Ignore terms that have a document frequency strictly lower than the given threshold.\n",
    "                                               # If float, the parameter represents a proportion of documents, integer absolute counts.\n",
    "                                               min_df=3,\n",
    "                                               # tf-idf parameters\n",
    "                                               use_idf=True, norm='l2', smooth_idf=False)),\n",
    "                         ('clf', SGDClassifier(loss='hinge',\n",
    "                                           penalty='l2',\n",
    "                                           tol=1e-5,\n",
    "                                           random_state=random_state))])\n",
    "# Model Training\n",
    "clf_pipeline.fit(input_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_pipeline.predict(input_test) # We are making prediction on the test set.\n",
    "print 'Accuracy: %.2f' % (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn` further provides utilities for a more detailed performance analysis of the results using different metrics (i.e. precision, recall, and f1-score). Support refers to the number of samples that belong to each particular class.\n",
    "\n",
    "For further details about those you can have a look [here](https://en.wikipedia.org/wiki/Precision_and_recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      insult       0.60      0.62      0.61       186\n",
      "     neutral       0.88      0.87      0.88       604\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       790\n",
      "   macro avg       0.74      0.75      0.74       790\n",
      "weighted avg       0.82      0.81      0.82       790\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, \n",
    "                                    y_pred,\n",
    "                                    target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like we did before, we can test how well our classifier is doing by inputing our own comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are such a moron: insult\n"
     ]
    }
   ],
   "source": [
    "test_comment = 'You are such a moron'\n",
    "y_pred = clf_pipeline.predict([test_comment])\n",
    "\n",
    "print'%s: %s' % (test_comment, class_names[y_pred[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try experimenting with different parameters (e.g. `ngram_range`, `tokenizer`, `max_df` or `min_df`) to see whether you achieve any better accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning using Grid Search\n",
    "We have already encountered some parameters such as `use_idf` in the `TfidfTransformer` (and `TfidfVectorizer`). Classifiers tend to have many parameters as well. For example `KNeighborsClassifier` includes parameter for the number of neighbours and `SGDClassifier` has a penalty parameter alpha and configurable loss and penalty terms in the objective function.\n",
    "\n",
    "Instead of tweaking the parameters of the various components of the chain, it is possible to run an exhaustive search of the best parameters on a grid of possible values. Let's use this to explore whether we can make the KNeighborsClassifier perform as well as our linear SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipeline = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                         ('clf', KNeighborsClassifier(n_neighbors=3))])\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__n_neighbors': (1, 3, 5, 7, 9)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, such an exhaustive search can be expensive. If we have multiple CPU cores at our disposal, we can tell the grid searcher to try these eleven parameter combinations in parallel with the `n_jobs` parameter. If we give this parameter a value of -1, grid search will detect how many cores are installed and uses them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipeline = GridSearchCV(knn_pipeline, param_grid=parameters, cv=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid search instance behaves like a normal `scikit-learn` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.float64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=T...ki',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform'))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'tfidf__use_idf': (True, False), 'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)], 'clf__n_neighbors': (1, 3, 5, 7, 9)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_pipeline.fit(input_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the optimal parameters out by inspecting the object's `grid_scores_` attribute, which is a list of parameters/score pairs. To get the best scoring attributes, we do as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf__use_idf: True\n",
      "tfidf__ngram_range: (1, 1)\n",
      "clf__n_neighbors: 9\n",
      "The best achieved accuracy is 0.81\n"
     ]
    }
   ],
   "source": [
    "for param_name in knn_pipeline.best_params_:\n",
    "    print(\"%s: %r\" % (param_name, knn_pipeline.best_params_[param_name]))\n",
    "print 'The best achieved accuracy is %.2f' % knn_pipeline.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test and see how well new comments are classified on our `knn_pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I do not agree!: neutral\n"
     ]
    }
   ],
   "source": [
    "test_comment = 'I do not agree!'\n",
    "y_pred = knn_pipeline.predict([test_comment])\n",
    "\n",
    "print'%s: %s' % (test_comment, class_names[y_pred[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring K-Means Clustering\n",
    "Now that we have extracted features from our training documents we're in a position to experiment with clustering. We will use K-Means as its one of the most intuitive clustering methods, although it does have a few limitations.\n",
    "\n",
    "K-Means clustering with 5 clusters can be achieved as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=5, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "num_clusters = 5\n",
    "k_means = KMeans(num_clusters)\n",
    "k_means.fit(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assignments of the original posts to cluster id is given by `km.labels_` once `km.fit(...)` has been called. The centroids of the clusters is given by `km.cluster_centers_`. Intuitively, the vector that describes the centre of a cluster is just like any other feature vector. An interesting way to explore what each cluster is representing is to calculate and print the top weighted (either by occurrence or tf-idf) terms for that cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:  sick\n",
      " fuck\n",
      " zero\n",
      " forgive\n",
      " followers\n",
      "Cluster 1:  xa0\n",
      " like\n",
      " just\n",
      " don\n",
      " fucking\n",
      "Cluster 2:  fuck\n",
      " google\n",
      " fag\n",
      " nget\n",
      " dad\n",
      "Cluster 3:  shit\n",
      " holy\n",
      " nice\n",
      " did\n",
      " zero\n",
      "Cluster 4:  idiot\n",
      " wrong\n",
      " need\n",
      " fucking\n",
      " don\n"
     ]
    }
   ],
   "source": [
    "order_centroids = k_means.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = tfidf_vect.get_feature_names()\n",
    "for i in range(num_clusters):\n",
    "    print \"Cluster %d:\" % i,\n",
    "    for ind in order_centroids[i, :5]:\n",
    "        print ' %s' % terms[ind],\n",
    "        print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A number of different metrics exist that allow us to measure how well the clusters fit the known distribution of underlying newsgroups. One such metric is the homogeneity which is a measure of how pure the clusters are with respect to the known labels (e.g. insult or neutral)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.012\n"
     ]
    }
   ],
   "source": [
    "print \"Homogeneity: %0.3f\" % metrics.homogeneity_score(y_train, k_means.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homogeneity scores vary between 0 and 1; a score of 1 indicates that the clusters match the original label distribution exactly.\n",
    "\n",
    "Explore what happens if you make the number of clusters larger. What do you notice? Do the clusters begin to make more intuitive sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have enjoyed this tutorial, the exercises in [Working With Data](http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html) are a good next step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
